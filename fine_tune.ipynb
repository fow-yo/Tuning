{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fine-tune.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install jsonlines"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqURwCKAyT09",
        "outputId": "b4f8ebe3-0236-4634-ca73-1d7aa101d648"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: jsonlines in /usr/local/lib/python3.7/dist-packages (3.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonlines) (4.1.1)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from jsonlines) (22.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jsonlines\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "XsFXZoBpxfU1"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_jsonlines(path):\n",
        "    with jsonlines.open(path, 'r') as reader:\n",
        "        text = []\n",
        "        for obj in reader:\n",
        "            for line in obj:\n",
        "              text.append(line)\n",
        "        return text"
      ],
      "metadata": {
        "id": "p0P6HF-3xbll"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = read_jsonlines('/content/input/mapping_original.jsonl')"
      ],
      "metadata": {
        "id": "5-1GCStNydks"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = text[:20]"
      ],
      "metadata": {
        "id": "68BP4N8P0SBE"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(text, test_size=0.3)"
      ],
      "metadata": {
        "id": "BH_PgE4jzl0E"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with jsonlines.open('/content/input/train.json', mode='w') as writer:\n",
        "        writer.write_all(train)"
      ],
      "metadata": {
        "id": "MA0yWglx1Trk"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with jsonlines.open('/content/input/validation.json', mode='w') as writer:\n",
        "        writer.write_all(test)"
      ],
      "metadata": {
        "id": "VrVcGXJJ1Xw0"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnncsBCOwQMU",
        "outputId": "3a7b3fbb-18c7-4631-8016-ec4bb15fec43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 106509, done.\u001b[K\n",
            "remote: Counting objects: 100% (131/131), done.\u001b[K\n",
            "remote: Compressing objects: 100% (47/47), done.\u001b[K\n",
            "remote: Total 106509 (delta 75), reused 109 (delta 68), pack-reused 106378\u001b[K\n",
            "Receiving objects: 100% (106509/106509), 98.52 MiB | 21.10 MiB/s, done.\n",
            "Resolving deltas: 100% (78688/78688), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/huggingface/transformers.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/transformers/\n",
        "!pip install . -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mH1yh8GJwR81",
        "outputId": "4e843e49-0c02-4807-fdf2-dbff7fed91b1"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/transformers\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/transformers/examples/pytorch/translation/requirements.txt -q"
      ],
      "metadata": {
        "id": "hmCksSMvwTTN"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/transformers/examples/pytorch/translation/run_translation.py \\\n",
        "    --model_name_or_path 'Helsinki-NLP/opus-mt-en-fr' \\\n",
        "    --do_train \\\n",
        "    --do_eval \\\n",
        "    --save_strategy steps \\\n",
        "    --source_lang en \\\n",
        "    --num_train_epochs 10 \\\n",
        "    --target_lang fr \\\n",
        "    --max_source_length 512 \\\n",
        "    --max_target_length 512 \\\n",
        "    --val_max_target_length 512 \\\n",
        "    --train_file '/content/input/train.json' \\\n",
        "    --validation_file '/content/input/validation.json' \\\n",
        "    --output_dir '/content/output' \\\n",
        "    --per_device_train_batch_size=2 \\\n",
        "    --per_device_eval_batch_size=4 \\\n",
        "    --overwrite_output_dir \\\n",
        "    --pad_to_max_length False \\\n",
        "    --save_steps 1000 \\\n",
        "    --evaluation_strategy steps \\\n",
        "    --logging_steps 5000 \\\n",
        "    --predict_with_generate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLWTUI7MwU3s",
        "outputId": "da1536bd-87c9-45d1-e37b-f68fc45f4127"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "08/26/2022 06:41:32 - WARNING - __main__ - Process rank: -1, device: cpu, n_gpu: 0distributed training: False, 16-bits training: False\n",
            "08/26/2022 06:41:32 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
            "_n_gpu=0,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=5000,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "generation_max_length=None,\n",
            "generation_num_beams=None,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=-1,\n",
            "log_level_replica=-1,\n",
            "log_on_each_node=True,\n",
            "logging_dir=/content/output/runs/Aug26_06-41-31_9efc3b3aaaf0,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=5000,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=10.0,\n",
            "optim=adamw_hf,\n",
            "output_dir=/content/output,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=4,\n",
            "per_device_train_batch_size=2,\n",
            "predict_with_generate=True,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=/content/output,\n",
            "save_on_each_node=False,\n",
            "save_steps=1000,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "sortish_sampler=False,\n",
            "tf32=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xpu_backend=None,\n",
            ")\n",
            "08/26/2022 06:41:33 - WARNING - datasets.builder - Using custom data configuration default-d46f6a8c31af78fa\n",
            "08/26/2022 06:41:33 - INFO - datasets.builder - Generating dataset json (/root/.cache/huggingface/datasets/json/default-d46f6a8c31af78fa/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253)\n",
            "Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-d46f6a8c31af78fa/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253...\n",
            "Downloading data files: 100% 2/2 [00:00<00:00, 9238.56it/s]\n",
            "08/26/2022 06:41:33 - INFO - datasets.download.download_manager - Downloading took 0.0 min\n",
            "08/26/2022 06:41:33 - INFO - datasets.download.download_manager - Checksum Computation took 0.0 min\n",
            "Extracting data files: 100% 2/2 [00:00<00:00, 775.29it/s]\n",
            "08/26/2022 06:41:33 - INFO - datasets.utils.info_utils - Unable to verify checksums.\n",
            "08/26/2022 06:41:33 - INFO - datasets.builder - Generating train split\n",
            "08/26/2022 06:41:33 - INFO - datasets.builder - Generating validation split\n",
            "08/26/2022 06:41:33 - INFO - datasets.utils.info_utils - Unable to verify splits sizes.\n",
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-d46f6a8c31af78fa/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253. Subsequent calls will reuse this data.\n",
            "100% 2/2 [00:00<00:00, 745.32it/s]\n",
            "[INFO|configuration_utils.py:643] 2022-08-26 06:41:34,095 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Helsinki-NLP--opus-mt-en-fr/snapshots/a8fbc1c711cb6263e8a20c5229b210cc05c57ff0/config.json\n",
            "[INFO|configuration_utils.py:695] 2022-08-26 06:41:34,099 >> Model config MarianConfig {\n",
            "  \"_name_or_path\": \"Helsinki-NLP/opus-mt-en-fr\",\n",
            "  \"_num_labels\": 3,\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"swish\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": false,\n",
            "  \"architectures\": [\n",
            "    \"MarianMTModel\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bad_words_ids\": [\n",
            "    [\n",
            "      59513\n",
            "    ]\n",
            "  ],\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_attention_heads\": 8,\n",
            "  \"decoder_ffn_dim\": 2048,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 6,\n",
            "  \"decoder_start_token_id\": 59513,\n",
            "  \"decoder_vocab_size\": 59514,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 8,\n",
            "  \"encoder_ffn_dim\": 2048,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 6,\n",
            "  \"eos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 0,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"max_length\": 512,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"marian\",\n",
            "  \"normalize_before\": false,\n",
            "  \"normalize_embedding\": false,\n",
            "  \"num_beams\": 4,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 59513,\n",
            "  \"scale_embedding\": true,\n",
            "  \"share_encoder_decoder_embeddings\": true,\n",
            "  \"static_position_embeddings\": true,\n",
            "  \"transformers_version\": \"4.22.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 59514\n",
            "}\n",
            "\n",
            "[INFO|configuration_utils.py:643] 2022-08-26 06:41:34,858 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Helsinki-NLP--opus-mt-en-fr/snapshots/a8fbc1c711cb6263e8a20c5229b210cc05c57ff0/config.json\n",
            "[INFO|configuration_utils.py:695] 2022-08-26 06:41:34,859 >> Model config MarianConfig {\n",
            "  \"_name_or_path\": \"Helsinki-NLP/opus-mt-en-fr\",\n",
            "  \"_num_labels\": 3,\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"swish\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": false,\n",
            "  \"architectures\": [\n",
            "    \"MarianMTModel\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bad_words_ids\": [\n",
            "    [\n",
            "      59513\n",
            "    ]\n",
            "  ],\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_attention_heads\": 8,\n",
            "  \"decoder_ffn_dim\": 2048,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 6,\n",
            "  \"decoder_start_token_id\": 59513,\n",
            "  \"decoder_vocab_size\": 59514,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 8,\n",
            "  \"encoder_ffn_dim\": 2048,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 6,\n",
            "  \"eos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 0,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"max_length\": 512,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"marian\",\n",
            "  \"normalize_before\": false,\n",
            "  \"normalize_embedding\": false,\n",
            "  \"num_beams\": 4,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 59513,\n",
            "  \"scale_embedding\": true,\n",
            "  \"share_encoder_decoder_embeddings\": true,\n",
            "  \"static_position_embeddings\": true,\n",
            "  \"transformers_version\": \"4.22.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 59514\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:1766] 2022-08-26 06:41:37,129 >> loading file source.spm from cache at /root/.cache/huggingface/hub/models--Helsinki-NLP--opus-mt-en-fr/snapshots/a8fbc1c711cb6263e8a20c5229b210cc05c57ff0/source.spm\n",
            "[INFO|tokenization_utils_base.py:1766] 2022-08-26 06:41:37,129 >> loading file target.spm from cache at /root/.cache/huggingface/hub/models--Helsinki-NLP--opus-mt-en-fr/snapshots/a8fbc1c711cb6263e8a20c5229b210cc05c57ff0/target.spm\n",
            "[INFO|tokenization_utils_base.py:1766] 2022-08-26 06:41:37,130 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--Helsinki-NLP--opus-mt-en-fr/snapshots/a8fbc1c711cb6263e8a20c5229b210cc05c57ff0/vocab.json\n",
            "[INFO|tokenization_utils_base.py:1766] 2022-08-26 06:41:37,130 >> loading file target_vocab.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1766] 2022-08-26 06:41:37,130 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--Helsinki-NLP--opus-mt-en-fr/snapshots/a8fbc1c711cb6263e8a20c5229b210cc05c57ff0/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1766] 2022-08-26 06:41:37,130 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1766] 2022-08-26 06:41:37,130 >> loading file special_tokens_map.json from cache at None\n",
            "[INFO|configuration_utils.py:643] 2022-08-26 06:41:37,130 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Helsinki-NLP--opus-mt-en-fr/snapshots/a8fbc1c711cb6263e8a20c5229b210cc05c57ff0/config.json\n",
            "[INFO|configuration_utils.py:695] 2022-08-26 06:41:37,131 >> Model config MarianConfig {\n",
            "  \"_name_or_path\": \"Helsinki-NLP/opus-mt-en-fr\",\n",
            "  \"_num_labels\": 3,\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"swish\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": false,\n",
            "  \"architectures\": [\n",
            "    \"MarianMTModel\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bad_words_ids\": [\n",
            "    [\n",
            "      59513\n",
            "    ]\n",
            "  ],\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_attention_heads\": 8,\n",
            "  \"decoder_ffn_dim\": 2048,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 6,\n",
            "  \"decoder_start_token_id\": 59513,\n",
            "  \"decoder_vocab_size\": 59514,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 8,\n",
            "  \"encoder_ffn_dim\": 2048,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 6,\n",
            "  \"eos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 0,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"max_length\": 512,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"marian\",\n",
            "  \"normalize_before\": false,\n",
            "  \"normalize_embedding\": false,\n",
            "  \"num_beams\": 4,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 59513,\n",
            "  \"scale_embedding\": true,\n",
            "  \"share_encoder_decoder_embeddings\": true,\n",
            "  \"static_position_embeddings\": true,\n",
            "  \"transformers_version\": \"4.22.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 59514\n",
            "}\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/marian/tokenization_marian.py:194: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
            "[INFO|modeling_utils.py:2067] 2022-08-26 06:41:37,359 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--Helsinki-NLP--opus-mt-en-fr/snapshots/a8fbc1c711cb6263e8a20c5229b210cc05c57ff0/pytorch_model.bin\n",
            "[INFO|modeling_utils.py:2501] 2022-08-26 06:41:40,738 >> All model checkpoint weights were used when initializing MarianMTModel.\n",
            "\n",
            "[INFO|modeling_utils.py:2510] 2022-08-26 06:41:40,738 >> All the weights of MarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-en-fr.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n",
            "Running tokenizer on train dataset:   0% 0/1 [00:00<?, ?ba/s]08/26/2022 06:41:41 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-d46f6a8c31af78fa/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253/cache-8c0bc15689ac3812.arrow\n",
            "Running tokenizer on train dataset: 100% 1/1 [00:00<00:00, 83.80ba/s]\n",
            "Running tokenizer on validation dataset:   0% 0/1 [00:00<?, ?ba/s]08/26/2022 06:41:41 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-d46f6a8c31af78fa/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253/cache-9f925fe12cd26325.arrow\n",
            "Running tokenizer on validation dataset: 100% 1/1 [00:00<00:00, 162.23ba/s]\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "[INFO|trainer.py:1612] 2022-08-26 06:41:43,383 >> ***** Running training *****\n",
            "[INFO|trainer.py:1613] 2022-08-26 06:41:43,383 >>   Num examples = 14\n",
            "[INFO|trainer.py:1614] 2022-08-26 06:41:43,383 >>   Num Epochs = 10\n",
            "[INFO|trainer.py:1615] 2022-08-26 06:41:43,383 >>   Instantaneous batch size per device = 2\n",
            "[INFO|trainer.py:1616] 2022-08-26 06:41:43,383 >>   Total train batch size (w. parallel, distributed & accumulation) = 2\n",
            "[INFO|trainer.py:1617] 2022-08-26 06:41:43,383 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:1618] 2022-08-26 06:41:43,383 >>   Total optimization steps = 70\n",
            "100% 70/70 [01:44<00:00,  1.45s/it][INFO|trainer.py:1857] 2022-08-26 06:43:27,776 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 104.3928, 'train_samples_per_second': 1.341, 'train_steps_per_second': 0.671, 'train_loss': 0.4300567626953125, 'epoch': 10.0}\n",
            "100% 70/70 [01:44<00:00,  1.49s/it]\n",
            "[INFO|trainer.py:2653] 2022-08-26 06:43:27,778 >> Saving model checkpoint to /content/output\n",
            "[INFO|configuration_utils.py:440] 2022-08-26 06:43:27,779 >> Configuration saved in /content/output/config.json\n",
            "[INFO|modeling_utils.py:1569] 2022-08-26 06:43:28,543 >> Model weights saved in /content/output/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2116] 2022-08-26 06:43:28,544 >> tokenizer config file saved in /content/output/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2123] 2022-08-26 06:43:28,544 >> Special tokens file saved in /content/output/special_tokens_map.json\n",
            "***** train metrics *****\n",
            "  epoch                    =       10.0\n",
            "  train_loss               =     0.4301\n",
            "  train_runtime            = 0:01:44.39\n",
            "  train_samples            =         14\n",
            "  train_samples_per_second =      1.341\n",
            "  train_steps_per_second   =      0.671\n",
            "08/26/2022 06:43:28 - INFO - __main__ - *** Evaluate ***\n",
            "[INFO|trainer.py:2904] 2022-08-26 06:43:28,656 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2906] 2022-08-26 06:43:28,656 >>   Num examples = 6\n",
            "[INFO|trainer.py:2909] 2022-08-26 06:43:28,656 >>   Batch size = 4\n",
            "100% 2/2 [00:03<00:00,  1.92s/it]\n",
            "***** eval metrics *****\n",
            "  epoch                   =       10.0\n",
            "  eval_bleu               =    35.6188\n",
            "  eval_gen_len            =    33.1667\n",
            "  eval_loss               =     1.1915\n",
            "  eval_runtime            = 0:00:10.08\n",
            "  eval_samples            =          6\n",
            "  eval_samples_per_second =      0.595\n",
            "  eval_steps_per_second   =      0.198\n",
            "[INFO|modelcard.py:443] 2022-08-26 06:43:39,507 >> Dropping the following result as it does not have all the necessary fields:\n",
            "{'task': {'name': 'Translation', 'type': 'translation'}, 'metrics': [{'name': 'Bleu', 'type': 'bleu', 'value': 35.6188}]}\n"
          ]
        }
      ]
    }
  ]
}